---
title: Blueprint Authoring Guide
description: Advanced guide for creating custom Renku blueprints and producers
---

This comprehensive guide explains how to author Renku blueprints: the YAML schema, how producers compose into workflows, and the rules the planner and runner enforce.

## Overview

Blueprints are YAML files that define complete video generation workflows. This guide is for advanced users who want to:

- Create custom blueprints for specific use cases
- Build reusable producers for new AI models
- Understand the internal workings of the planner and runner

If you're new to Renku, start with the [Quick Start](/docs/quick-start) guide first.

## Core Concepts

### Blueprint vs Producer

**Blueprints** are workflow definitions that:
- Define user-facing inputs and final artifacts
- Import and connect multiple producers
- Define loops for parallel execution
- Specify collectors for fan-in aggregation

**Producers** are execution units that:
- Accept inputs and produce artifacts
- Map inputs to specific AI model parameters
- Support multiple model variants
- Can be reused across multiple blueprints

### Data Flow

Data flows through the system via connections:

```
Blueprint Input → Producer Input → Producer → Artifact → Next Producer Input
                                                   │
                                                   └→ Blueprint Artifact
```

For looped producers:
```
ScriptProducer.NarrationScript[0] → AudioProducer[0].TextInput
ScriptProducer.NarrationScript[1] → AudioProducer[1].TextInput
ScriptProducer.NarrationScript[2] → AudioProducer[2].TextInput
```

---

## Blueprint YAML Reference

### Complete Schema

```yaml
meta:
  name: <string>           # Human-readable name (required)
  description: <string>    # Purpose and behavior
  id: <string>             # Unique identifier in PascalCase (required)
  version: <semver>        # Semantic version (e.g., 0.1.0)
  author: <string>         # Creator name
  license: <string>        # License type (e.g., MIT)

inputs:
  - name: <string>         # Input identifier in PascalCase (required)
    description: <string>  # Purpose and usage
    type: <string>         # Data type (required)
    required: <boolean>    # Whether mandatory (default: true)

artifacts:
  - name: <string>         # Artifact identifier in PascalCase (required)
    description: <string>  # Purpose and content
    type: <string>         # Output type (required)
    itemType: <string>     # Element type for arrays
    countInput: <string>   # Input that determines array size

loops:
  - name: <string>         # Loop identifier in lowercase (required)
    description: <string>  # Purpose and behavior
    countInput: <string>   # Input that determines iteration count (required)
    countInputOffset: <int> # Offset added to count
    parent: <string>       # Parent loop for nesting

producers:
  - name: <string>         # Producer instance name in PascalCase (required)
    path: <string>         # Relative path to producer YAML (required)
    loop: <string>         # Loop dimension(s) (e.g., "segment")

connections:
  - from: <string>         # Source reference (required)
    to: <string>           # Target reference (required)
    if: <string>           # Condition name for conditional execution

conditions:
  <conditionName>:
    when: <string>         # Path to artifact field (e.g., Producer.Artifact.Field[dim])
    is: <any>              # Equals this value
    isNot: <any>           # Does not equal this value
    contains: <string>     # String contains value
    greaterThan: <number>  # Greater than
    lessThan: <number>     # Less than
    exists: <boolean>      # Field exists and is truthy
    matches: <string>      # Regex pattern
    all: <array>           # AND: all sub-conditions must pass
    any: <array>           # OR: at least one sub-condition must pass

collectors:
  - name: <string>         # Collector identifier (required)
    from: <string>         # Source artifact reference (required)
    into: <string>         # Target input reference (required)
    groupBy: <string>      # Loop dimension for grouping (required)
    orderBy: <string>      # Loop dimension for ordering
```

### Input Types

| Type | Description |
|------|-------------|
| `string` | Text value |
| `int` | Integer number |
| `image` | Image file reference |
| `audio` | Audio file reference |
| `video` | Video file reference |
| `json` | Structured JSON data |
| `collection` | Array of items (used with `fanIn: true`) |

### Artifact Types

| Type | Description |
|------|-------------|
| `string` | Text output |
| `json` | Structured JSON with virtual property expansion (see [JSON Artifacts](#json-artifacts)) |
| `image` | Image file |
| `audio` | Audio file |
| `video` | Video file |
| `array` | Array of items (requires `itemType`) |
| `multiDimArray` | Multi-dimensional array |

### Example Blueprint

```yaml
meta:
  name: Video Only Narration
  description: Generate video segments from a textual inquiry.
  id: Video
  version: 0.1.0
  author: Renku
  license: MIT

inputs:
  - name: InquiryPrompt
    description: The prompt describing the movie script.
    type: string
    required: true
  - name: Duration
    description: Desired duration in seconds.
    type: int
    required: true
  - name: NumOfSegments
    description: Number of narration segments.
    type: int
    required: true
  - name: Style
    description: Visual style for the video.
    type: string
    required: true

artifacts:
  - name: SegmentVideo
    description: Generated video for each segment.
    type: array
    itemType: video
    countInput: NumOfSegments

loops:
  - name: segment
    description: Iterates over narration segments.
    countInput: NumOfSegments

producers:
  - name: ScriptProducer
    path: ../../producers/script/script.yaml
  - name: VideoPromptProducer
    path: ../../producers/video-prompt/video-prompt.yaml
  - name: VideoProducer
    path: ../../producers/video/video.yaml
    loop: segment

connections:
  # Wire inputs to ScriptProducer
  - from: InquiryPrompt
    to: ScriptProducer.InquiryPrompt
  - from: Duration
    to: ScriptProducer.Duration
  - from: NumOfSegments
    to: ScriptProducer.NumOfSegments

  # Wire script to VideoPromptProducer (looped)
  - from: ScriptProducer.NarrationScript[segment]
    to: VideoPromptProducer[segment].NarrativeText
  - from: Style
    to: VideoPromptProducer[segment].Style

  # Wire prompts to VideoProducer (looped)
  - from: VideoPromptProducer.VideoPrompt[segment]
    to: VideoProducer[segment].Prompt

  # Wire output to blueprint artifact
  - from: VideoProducer[segment].SegmentVideo
    to: SegmentVideo[segment]
```

---

## Producer YAML Reference

### Complete Schema

```yaml
meta:
  name: <string>           # Human-readable name (required)
  description: <string>    # Purpose and behavior
  id: <string>             # Unique identifier in PascalCase (required)
  version: <semver>        # Semantic version
  author: <string>         # Creator name
  license: <string>        # License type
  promptFile: <string>     # Path to TOML prompt config (LLM producers only)
  outputSchema: <string>   # Path to JSON schema for structured output (LLM producers only)

inputs:
  - name: <string>         # Input identifier (required)
    description: <string>  # Purpose and usage
    type: <string>         # Data type (required)
    fanIn: <boolean>       # Is this a fan-in collection input
    dimensions: <string>   # Dimension labels (e.g., "segment")

artifacts:
  - name: <string>         # Artifact identifier (required)
    description: <string>  # Purpose and content
    type: <string>         # Output type (required)
    itemType: <string>     # Element type for arrays
    countInput: <string>   # Input for array size

models:
  - provider: <string>     # Provider: openai, replicate, fal-ai, renku
    model: <string>        # Model identifier (required)
    inputs:                # Input field mappings
      <ProducerInput>: <providerField>
    config: <object>       # Provider-specific config
```

**Note on LLM Producers:** For producers that use LLMs (OpenAI, etc.), the `promptFile` and `outputSchema` fields are defined in the `meta:` section of the producer YAML file, not in the input template. These are intrinsic to the producer's functionality and cannot be overridden per-run.

### Example: Script Producer (OpenAI)

```yaml
meta:
  name: Script Generation
  description: Generate documentary scripts.
  id: ScriptProducer
  version: 0.1.0
  promptFile: ./script.toml              # Prompt template for LLM
  outputSchema: ./script-output.json     # JSON schema for structured output

inputs:
  - name: InquiryPrompt
    type: string
  - name: Duration
    type: int
  - name: NumOfSegments
    type: int
  - name: Audience
    type: string

artifacts:
  - name: MovieTitle
    type: string
  - name: MovieSummary
    type: string
  - name: NarrationScript
    type: array
    itemType: string
    countInput: NumOfSegments
```

**Note:** LLM producers define `promptFile` and `outputSchema` in the `meta:` section. The model selection (e.g., `gpt-4o`) is specified in the input template file.

### Example: Video Producer (Replicate)

```yaml
meta:
  name: Video Generation
  id: VideoProducer
  version: 0.1.0

inputs:
  - name: Prompt
    type: string
  - name: AspectRatio
    type: string
  - name: Resolution
    type: string

artifacts:
  - name: SegmentVideo
    type: video

models:
  - model: bytedance/seedance-1-pro-fast
    provider: replicate
    inputs:
      Prompt: prompt
      AspectRatio: aspect_ratio
      Resolution: resolution
  - model: google/veo-3.1-fast
    provider: replicate
    inputs:
      Prompt: prompt
      AspectRatio: aspect_ratio
```

### Example: Timeline Composer (Fan-In)

```yaml
meta:
  name: Timeline Composer
  id: TimelineComposer
  version: 0.1.0

inputs:
  - name: VideoSegments
    type: collection
    itemType: video
    dimensions: segment
    fanIn: true
  - name: AudioSegments
    type: collection
    itemType: audio
    dimensions: segment
    fanIn: true
  - name: Duration
    type: int

artifacts:
  - name: Timeline
    type: json

models:
  - model: timeline/ordered
    provider: renku
```

---

## Connections

Connections define data flow between nodes.

### Direct Connections

```yaml
connections:
  - from: InquiryPrompt
    to: ScriptProducer.InquiryPrompt
```

### Array Indexing

```yaml
connections:
  - from: ScriptProducer.NarrationScript[segment]
    to: AudioProducer[segment].TextInput
```

Expands to:
- `NarrationScript[0]` → `AudioProducer[0].TextInput`
- `NarrationScript[1]` → `AudioProducer[1].TextInput`
- etc.

### Multi-Dimensional Indexing

```yaml
connections:
  - from: ImageGenerator[segment][image].SegmentImage
    to: SegmentImage[segment][image]
```

### Offset Selectors

```yaml
connections:
  - from: ImageProducer[image].SegmentImage
    to: ImageToVideoProducer[segment].InputImage1
  - from: ImageProducer[image+1].SegmentImage
    to: ImageToVideoProducer[segment].InputImage2
```

Creates sliding window patterns. For N segments, you need N+1 images.

### Broadcast Connections

A scalar input broadcasts to all loop instances:

```yaml
connections:
  - from: Style
    to: VideoPromptProducer[segment].Style
```

### Connecting to JSON Artifact Properties

When a producer outputs a `type: json` artifact with a schema, you can connect to nested properties using dot-path syntax:

```yaml
connections:
  # Connect to top-level property
  - from: DocProducer.VideoScript.Title
    to: TitleRenderer.Title

  # Connect to array element property
  - from: DocProducer.VideoScript.Segments[segment].Script
    to: AudioProducer[segment].TextInput

  # Connect to nested array property
  - from: DocProducer.VideoScript.Segments[segment].ImagePrompts[image].Prompt
    to: ImageProducer[segment][image].Prompt
```

See [JSON Artifacts](#json-artifacts) for full details on defining JSON artifacts with schemas.

### Conditional Connections

Connections can be made conditional based on runtime values from upstream artifacts. This enables dynamic workflow branching where different producers execute depending on the data produced earlier in the pipeline.

#### Defining Conditions

Define named conditions in the `conditions:` section of your blueprint:

```yaml
conditions:
  isImageNarration:
    when: DocProducer.VideoScript.Segments[segment].NarrationType
    is: "ImageNarration"
  isAudioNeeded:
    any:
      - when: DocProducer.VideoScript.Segments[segment].NarrationType
        is: "TalkingHead"
      - when: DocProducer.VideoScript.Segments[segment].UseNarrationAudio
        is: true
  isTalkingHead:
    when: DocProducer.VideoScript.Segments[segment].NarrationType
    is: "TalkingHead"
```

#### Condition Path Format

The `when` field references a path to a value in an upstream artifact:

```
<Producer>.<Artifact>.<FieldPath>[dimension]
```

- **Producer**: The producer that creates the artifact (e.g., `DocProducer`)
- **Artifact**: The artifact name (e.g., `VideoScript`)
- **FieldPath**: Dot-separated path to the field (e.g., `Segments[segment].NarrationType`)
- **Dimensions**: Use dimension placeholders like `[segment]` for per-instance evaluation

#### Condition Operators

| Operator | Description |
|----------|-------------|
| `is` | Equals the specified value |
| `isNot` | Does not equal the specified value |
| `contains` | String contains the value |
| `greaterThan` | Greater than (numeric) |
| `lessThan` | Less than (numeric) |
| `greaterOrEqual` | Greater than or equal (numeric) |
| `lessOrEqual` | Less than or equal (numeric) |
| `exists` | Field exists and is truthy |
| `matches` | Matches a regular expression |

#### Condition Groups

Combine multiple conditions with `all` (AND) or `any` (OR):

```yaml
conditions:
  needsAudio:
    any:
      - when: DocProducer.VideoScript.Segments[segment].NarrationType
        is: "TalkingHead"
      - when: DocProducer.VideoScript.Segments[segment].UseNarrationAudio
        is: true

  isHighQuality:
    all:
      - when: DocProducer.VideoScript.Segments[segment].Quality
        is: "high"
      - when: DocProducer.VideoScript.Segments[segment].Duration
        greaterThan: 10
```

#### Using Conditions on Connections

Reference a named condition using the `if:` attribute:

```yaml
connections:
  # ImageProducer only runs when NarrationType is "ImageNarration"
  - from: DocProducer.VideoScript.Segments[segment].ImagePrompts[image]
    to: ImageProducer[segment][image].Prompt
    if: isImageNarration

  # AudioProducer runs when TalkingHead OR UseNarrationAudio is true
  - from: DocProducer.VideoScript.Segments[segment].Script
    to: AudioProducer[segment].TextInput
    if: isAudioNeeded
```

#### Runtime Behavior

When a condition is evaluated at runtime:

1. **Condition Evaluation**: The runner resolves the artifact data and evaluates the condition for each dimension instance
2. **Input Filtering**: If a condition is not satisfied, that input is filtered out
3. **Job Skipping**: If ALL conditional inputs for a job are not satisfied, the job is **skipped**
4. **Artifact Absence**: Skipped jobs produce no artifacts - those artifact IDs are absent from the manifest

**Example**: With 3 segments where `NarrationType = ["ImageNarration", "TalkingHead", "ImageNarration"]`:
- `ImageProducer[0]` and `ImageProducer[2]` execute (ImageNarration)
- `ImageProducer[1]` is skipped (TalkingHead)
- `AudioProducer[1]` executes (TalkingHead)
- `AudioProducer[0]` and `AudioProducer[2]` may be skipped (unless UseNarrationAudio=true)

---

## JSON Artifacts

JSON artifacts store structured data as a single blob while exposing nested properties as virtual artifacts for granular connections. This enables:

- **Granular connections**: Wire individual properties to downstream producers
- **Efficient caching**: Only re-run downstream jobs when specific properties change
- **Schema validation**: Structured output from LLMs with JSON schema enforcement

### Defining JSON Artifacts in Producers

```yaml
meta:
  id: DocumentaryPromptProducer
  name: Documentary Script Generation
  promptFile: ./documentary-prompt.toml           # Prompt template
  outputSchema: ./documentary-prompt-output.json  # JSON schema for validation

inputs:
  - name: InquiryPrompt
    type: string
  - name: NumOfSegments
    type: int
  - name: NumOfImagesPerSegment
    type: int
    default: 1

artifacts:
  - name: VideoScript
    type: json
    description: The generated video script
    arrays:
      - path: Segments
        countInput: NumOfSegments
      - path: Segments.ImagePrompts
        countInput: NumOfImagesPerSegment
```

**Note:** The model selection (e.g., `gpt-4o`) is specified in the input template file, not in the producer.

### The `arrays` Field

The `arrays` field maps JSON array paths to input variables that determine their sizes:

```yaml
arrays:
  - path: Segments                    # Top-level array
    countInput: NumOfSegments         # Sized by NumOfSegments input
  - path: Segments.ImagePrompts       # Nested array within each segment
    countInput: NumOfImagesPerSegment # Sized by NumOfImagesPerSegment input
```

This enables the planner to:
1. Create dimension placeholders for arrays (e.g., `[segment]`, `[image]`)
2. Expand virtual artifacts for each array element
3. Track granular changes for incremental re-runs

### Schema Association

The `outputSchema` from the producer's `meta:` section is automatically associated with `type: json` artifacts. The schema defines the structure of the JSON output:

```json
{
  "name": "VideoScript",
  "strict": true,
  "schema": {
    "type": "object",
    "properties": {
      "Title": { "type": "string" },
      "Segments": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "Script": { "type": "string" },
            "ImagePrompts": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "Prompt": { "type": "string" }
                }
              }
            }
          }
        }
      }
    }
  }
}
```

### Virtual Artifact Paths

The planner expands JSON schemas into virtual artifacts that can be referenced in connections:

| Virtual Artifact ID | Description |
|---------------------|-------------|
| `Producer.VideoScript.Title` | Top-level string property |
| `Producer.VideoScript.Segments[segment].Script` | Script for each segment |
| `Producer.VideoScript.Segments[segment].ImagePrompts[image].Prompt` | Image prompt for each segment/image |

### Granular Dirty Tracking

Each virtual artifact gets its own content hash. When you edit a JSON artifact:

- Only virtual artifacts whose content actually changed are marked dirty
- Only downstream jobs consuming those specific properties re-run
- Other downstream jobs use cached results

**Example**: If you edit only `Segments[1].Script`, only `AudioProducer[1]` re-runs. `AudioProducer[0]` and `AudioProducer[2]` use cached results.

---

## Loops and Dimensions

### Basic Loop

```yaml
loops:
  - name: segment
    countInput: NumOfSegments
```

If `NumOfSegments = 3`, looped producers run 3 times.

### Loop with Offset

```yaml
loops:
  - name: image
    countInput: NumOfSegments
    countInputOffset: 1
```

Count is `NumOfSegments + 1`. Use for sliding window patterns.

### Nested Loops

```yaml
loops:
  - name: segment
    countInput: NumOfSegments
  - name: image
    parent: segment
    countInput: NumOfImagesPerSegment
```

Creates two-dimensional iteration. If `NumOfSegments = 3` and `NumOfImagesPerSegment = 2`, you get 6 instances.

### Assigning Producers to Loops

```yaml
producers:
  - name: ScriptProducer
    path: ./script.yaml
    # No loop - runs once

  - name: AudioProducer
    path: ./audio.yaml
    loop: segment
    # Runs per segment

  - name: ImageProducer
    path: ./image.yaml
    loop: segment.image
    # Runs per segment × image
```

---

## Collectors and Fan-In

Collectors aggregate multiple artifacts for downstream processing.

### Basic Collector

```yaml
collectors:
  - name: TimelineVideo
    from: VideoProducer[segment].SegmentVideo
    into: TimelineComposer.VideoSegments
    groupBy: segment
```

### Collector with Ordering

```yaml
collectors:
  - name: TimelineImages
    from: ImageProducer[segment][image].SegmentImage
    into: TimelineComposer.ImageSegments
    groupBy: segment
    orderBy: image
```

### Fan-In Inputs

The target input must have `fanIn: true`:

```yaml
inputs:
  - name: VideoSegments
    type: collection
    itemType: video
    dimensions: segment
    fanIn: true
```

---

## Canonical IDs

Canonical IDs are fully qualified node identifiers.

### Format

```
Type:path.to.name[index0][index1]...
```

### Examples

| ID | Description |
|----|-------------|
| `Input:InquiryPrompt` | Blueprint input |
| `Input:ScriptProducer.Duration` | Producer input |
| `Artifact:VideoProducer.SegmentVideo[0]` | First video |
| `Artifact:ImageProducer.SegmentImage[2][1]` | Image at [2][1] |
| `Producer:AudioProducer[0]` | First AudioProducer instance |

---

## Planner and Runner

### Planner Process

1. **Load blueprint tree** - Blueprint + all producer imports
2. **Build graph** - Nodes for inputs, artifacts, producers
3. **Resolve dimensions** - Calculate loop sizes
4. **Expand instances** - Create concrete instances per dimension
5. **Align edges** - Match dimension indices
6. **Build execution layers** - Topological sort into parallel groups

### Runner Process

1. **Execute layer by layer** - Jobs in same layer can run in parallel
2. **Resolve artifacts** - Load upstream data for each job
3. **Materialize fan-in** - Group and order collection items
4. **Invoke providers** - Call AI APIs
5. **Store artifacts** - Persist to blob storage

### Dirty Tracking

For incremental runs:
1. Compare input hashes against manifest
2. Find changed or missing artifacts
3. Mark affected jobs as dirty
4. Propagate through dependency graph
5. Only execute dirty jobs

---

## Input Files Reference

### Structure

```yaml
inputs:
  InquiryPrompt: "Your topic here"
  Duration: 60
  NumOfSegments: 3

models:
  - model: minimax/speech-2.6-hd
    provider: replicate
    producerId: AudioProducer
  - model: bytedance/seedance-1-pro-fast
    provider: replicate
    producerId: VideoProducer
```

### Model Selection

Override default models per producer:

```yaml
models:
  - model: google/veo-3.1-fast
    provider: replicate
    producerId: VideoProducer
  - model: timeline/ordered
    provider: renku
    producerId: TimelineComposer
    config:
      masterTrack: Audio
      musicClip:
        volume: 0.4
```

---

## Validation Rules

### Blueprint Validation

| Rule | Error |
|------|-------|
| Meta section required | `Blueprint must have a meta section` |
| Meta.id required | `Blueprint meta must have an id` |
| At least one artifact | `Blueprint must declare at least one artifact` |
| Cannot mix models and producers | `Cannot define both models and producer imports` |

### Input Validation

| Rule | Error |
|------|-------|
| Optional inputs need defaults | `Optional input must declare a default value` |
| Input name required | `Input must have a name` |
| Input type required | `Input must have a type` |

### Connection Validation

| Rule | Error |
|------|-------|
| Valid dimension syntax | `Invalid dimension selector` |
| Known dimension | `Unknown loop symbol` |
| Dimension count match | `Inconsistent dimension counts` |

---

## Common Patterns

### Audio-Only Narration

```yaml
loops:
  - name: segment
    countInput: NumOfSegments

producers:
  - name: ScriptProducer
    path: ./script.yaml
  - name: AudioProducer
    path: ./audio.yaml
    loop: segment

connections:
  - from: ScriptProducer.NarrationScript[segment]
    to: AudioProducer[segment].TextInput
  - from: AudioProducer[segment].SegmentAudio
    to: SegmentAudio[segment]
```

### Image-to-Video (Sliding Window)

```yaml
loops:
  - name: segment
    countInput: NumOfSegments
  - name: image
    countInput: NumOfSegments
    countInputOffset: 1  # N+1 images

producers:
  - name: ImageProducer
    path: ./image.yaml
    loop: image
  - name: ImageToVideoProducer
    path: ./image-to-video.yaml
    loop: segment

connections:
  - from: ImageProducer[image].SegmentImage
    to: ImageToVideoProducer[segment].InputImage1
  - from: ImageProducer[image+1].SegmentImage
    to: ImageToVideoProducer[segment].InputImage2
```

### Full Timeline

```yaml
producers:
  - name: VideoProducer
    path: ./video.yaml
    loop: segment
  - name: AudioProducer
    path: ./audio.yaml
    loop: segment
  - name: TimelineComposer
    path: ./timeline-composer.yaml

collectors:
  - name: TimelineVideo
    from: VideoProducer[segment].SegmentVideo
    into: TimelineComposer.VideoSegments
    groupBy: segment
  - name: TimelineAudio
    from: AudioProducer[segment].SegmentAudio
    into: TimelineComposer.AudioSegments
    groupBy: segment
```

---

## Debugging

### Validate Blueprint

```bash
renku blueprints:validate ./my-blueprint.yaml
```

### Dry Run

```bash
renku generate --inputs=./inputs.yaml --blueprint=./blueprint.yaml --dry-run
```

### Inspect Execution Plan

```bash
cat {builds}/{movie}/runs/rev-0001-plan.json
```

### Common Issues

| Problem | Cause | Solution |
|---------|-------|----------|
| Fan-in empty | Missing collector | Add collector from source to target |
| Dimension error | Mismatched dimensions | Verify source/target dimensions match |
| Optional input error | Missing default | Add `default:` to optional inputs |
| Missing artifacts | Wrong build path | Check `dist/` per package |

---

## Directory Structure

### Catalog Organization

```
catalog/
├── blueprints/
│   ├── audio-only/
│   │   ├── audio-only.yaml
│   │   └── input-template.yaml
│   └── video-only/
│       ├── video-only.yaml
│       └── input-template.yaml
├── producers/
│   ├── script/
│   │   ├── script.yaml
│   │   └── script.toml
│   ├── audio/
│   │   └── audio.yaml
│   └── video/
│       └── video.yaml
└── models/
    └── *.yaml
```

### Naming Conventions

| Item | Convention | Example |
|------|------------|---------|
| Blueprint files | kebab-case | `image-to-video.yaml` |
| Producer files | kebab-case | `script.yaml` |
| IDs | PascalCase | `id: ImageToVideo` |
| Loop names | lowercase | `name: segment` |
| Input/Artifact names | PascalCase | `name: InquiryPrompt` |

### Relative Paths

Producer paths are relative to the blueprint file:

```yaml
# In blueprints/video-only/video-only.yaml
producers:
  - name: ScriptProducer
    path: ../../producers/script/script.yaml
```
